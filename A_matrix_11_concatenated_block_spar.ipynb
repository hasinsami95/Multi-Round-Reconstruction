{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import numba\n",
    "#import cupy as cp\n",
    "#l=np.load('arr.npy')\n",
    "#print(l)\n",
    "# l=np.load('gradient.npy')\n",
    "# print(len(l[0]))\n",
    "from scipy.sparse import csr_matrix, save_npz, load_npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.25.2\n"
     ]
    }
   ],
   "source": [
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg1=np.array(np.load(\"err1_in_block.npy\")) #, allow_pickle=True))\n",
    "agg1=agg1.transpose()\n",
    "A_conc1=np.load(\"A_conc1_in_block.npy\", allow_pickle=True)                  #np.load(\"A_conc1_in.npy\")\n",
    "A_con=[]\n",
    "iter_no=5\n",
    "for i in range(iter_no):\n",
    "    A_con.append(A_conc1[i].todense())\n",
    "A_conc1=np.array(A_con)\n",
    "A_conc1= np.concatenate(A_conc1, axis=1)\n",
    "#np.save(\"agg3.npy\",agg3)\n",
    "\n",
    "# del err1\n",
    "# del err2\n",
    "# del err3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1862327, 5)\n"
     ]
    }
   ],
   "source": [
    "print(A_conc1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(A_conc1)\n",
    "# #print(A_conc1[:,[0:300]])\n",
    "# print(A_conc1[0][0:1000].shape)\n",
    "# A=np.zeros(A_conc1.shape[0])\n",
    "# for t in range(A_conc1.shape[0]):\n",
    "#     A[t]=A_conc1[0][0:200]\n",
    "# print(A)\n",
    "# print(np.array(A).shape)\n",
    "A=A_conc1[:, :1000]\n",
    "# print(A.shape)\n",
    "# print(A)\n",
    "# print(A_conc1[1862324][0:1000])\n",
    "A_conc1=A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 9311635)\n"
     ]
    }
   ],
   "source": [
    "print(A_conc1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg1_2=np.array(np.load(\"err1_in_2_topK.npy\")) #, allow_pickle=True))\n",
    "agg1_2=agg1_2.transpose()\n",
    "A_conc1_2=np.load(\"A_conc1_in_2_topK.npy\", allow_pickle=True)                  #np.load(\"A_conc1_in.npy\")\n",
    "A_con=[]\n",
    "iter_no=500\n",
    "for i in range(iter_no):\n",
    "    A_con.append(A_conc1_2[i].todense())\n",
    "A_conc1_2=np.array(A_con)\n",
    "A_conc1_2= np.concatenate(A_conc1_2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg1_3=np.array(np.load(\"err1_in_3_topK.npy\")) #, allow_pickle=True))\n",
    "agg1_3=agg1_3.transpose()\n",
    "A_conc1_3=np.load(\"A_conc1_in_3_topK.npy\", allow_pickle=True)                  #np.load(\"A_conc1_in.npy\")\n",
    "A_con=[]\n",
    "iter_no=500\n",
    "for i in range(iter_no):\n",
    "    A_con.append(A_conc1_3[i].todense())\n",
    "A_conc1_3=np.array(A_con)\n",
    "A_conc1_3= np.concatenate(A_conc1_3, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg1_4=np.array(np.load(\"err1_in_4_topK.npy\")) #, allow_pickle=True))\n",
    "agg1_4=agg1_4.transpose()\n",
    "A_conc1_4=np.load(\"A_conc1_in_4_topK.npy\", allow_pickle=True)                  #np.load(\"A_conc1_in.npy\")\n",
    "A_con=[]\n",
    "iter_no=500\n",
    "for i in range(iter_no):\n",
    "    A_con.append(A_conc1_4[i].todense())\n",
    "A_conc1_4=np.array(A_con)\n",
    "A_conc1_4= np.concatenate(A_conc1_4, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg1_5=np.array(np.load(\"err1_in_5_topK.npy\")) #, allow_pickle=True))\n",
    "agg1_5=agg1_5.transpose()\n",
    "A_conc1_5=np.load(\"A_conc1_in_5_topK.npy\", allow_pickle=True)                  #np.load(\"A_conc1_in.npy\")\n",
    "A_con=[]\n",
    "iter_no=500\n",
    "for i in range(iter_no):\n",
    "    A_con.append(A_conc1_5[i].todense())\n",
    "A_conc1_5=np.array(A_con)\n",
    "A_conc1_5= np.concatenate(A_conc1_5, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg1 = np.concatenate((agg1, agg1_2 ), axis=1) #, , agg1_3, agg1_4 agg1_3, agg1_4 #, agg1_4, agg1_5\n",
    "print(agg1.shape)\n",
    "A_conc1 = np.concatenate((A_conc1, A_conc1_2 ), axis=1) #,, A_conc1_3, A_conc1_4 A_conc1_4, A_conc1_5\n",
    "print(A_conc1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del agg1_2\n",
    "# del agg1_3\n",
    "# del agg1_4\n",
    "# del agg1_5\n",
    "#del A_conc1_2\n",
    "# del A_conc1_3\n",
    "# del A_conc1_4\n",
    "# del A_conc1_5\n",
    "import torch\n",
    "torch.cuda.empty_cache()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "  dev = \"cuda:1\"\n",
    "else:\n",
    "  dev = \"cpu\"\n",
    "device = torch.device(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Managed Device 0>, <Managed Device 1>, <Managed Device 2>, <Managed Device 3>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<weakproxy at 0x7f7c6d23c360 to Device at 0x7f7c6d232850>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numba import cuda\n",
    "from numba import jit\n",
    "print(cuda.gpus)\n",
    "numba.cuda.select_device( 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.25.2\n"
     ]
    }
   ],
   "source": [
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 CUDA devices\n",
      "id 0     b'NVIDIA RTX A5000'                              [SUPPORTED]\n",
      "                      Compute Capability: 8.6\n",
      "                           PCI Device ID: 0\n",
      "                              PCI Bus ID: 1\n",
      "                                    UUID: GPU-40bcd8b4-5cb3-da50-8697-9eb0132c32ce\n",
      "                                Watchdog: Enabled\n",
      "             FP32/FP64 Performance Ratio: 32\n",
      "id 1     b'NVIDIA RTX A5000'                              [SUPPORTED]\n",
      "                      Compute Capability: 8.6\n",
      "                           PCI Device ID: 0\n",
      "                              PCI Bus ID: 46\n",
      "                                    UUID: GPU-222a9771-0647-f35f-3d4d-9c45e0814331\n",
      "                                Watchdog: Enabled\n",
      "             FP32/FP64 Performance Ratio: 32\n",
      "id 2     b'NVIDIA RTX A5000'                              [SUPPORTED]\n",
      "                      Compute Capability: 8.6\n",
      "                           PCI Device ID: 0\n",
      "                              PCI Bus ID: 65\n",
      "                                    UUID: GPU-28530142-37b2-3101-cf9c-4987c62589f1\n",
      "                                Watchdog: Enabled\n",
      "             FP32/FP64 Performance Ratio: 32\n",
      "id 3     b'NVIDIA RTX A5000'                              [SUPPORTED]\n",
      "                      Compute Capability: 8.6\n",
      "                           PCI Device ID: 0\n",
      "                              PCI Bus ID: 97\n",
      "                                    UUID: GPU-460987e3-1b91-0570-1cd7-d55ac9afd83f\n",
      "                                Watchdog: Enabled\n",
      "             FP32/FP64 Performance Ratio: 32\n",
      "Summary:\n",
      "\t4/4 devices are supported\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_63728/2804947012.py:6: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  def matrix_comp(A,A_conc,d,iter_no):\n"
     ]
    }
   ],
   "source": [
    "from numba import cuda\n",
    "cuda.detect()\n",
    "from numba import jit\n",
    "#@cuda.jit\n",
    "@jit #(target='cuda:1')\n",
    "def matrix_comp(A,A_conc,d,iter_no):\n",
    "    #for t in range(int(d/6)):\n",
    "    for t in range(A_conc.shape[0]):\n",
    "#     if (t%500000)==0:\n",
    "#         print(t)\n",
    "    #for j in range(user_no):\n",
    "        A[t]=np.split(A_conc[t],iter_no)\n",
    "        #A[t]=np.ma.row_stack (A[t])\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(numba.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_63728/2804947012.py:5: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"matrix_comp\" failed type inference due to: No implementation of function Function(<built-in function setitem>) found for signature:\n",
      " \n",
      " >>> setitem(array(float64, 3d, C), int64, list(array(uint16, 1d, C))<iv=None>)\n",
      " \n",
      "There are 16 candidate implementations:\n",
      "      - Of which 16 did not match due to:\n",
      "      Overload of function 'setitem': File: <numerous>: Line N/A.\n",
      "        With argument(s): '(array(float64, 3d, C), int64, list(array(uint16, 1d, C))<iv=None>)':\n",
      "       No match.\n",
      "\n",
      "During: typing of setitem at /tmp/ipykernel_63728/2804947012.py (12)\n",
      "\n",
      "File \"../../../../../tmp/ipykernel_63728/2804947012.py\", line 12:\n",
      "<source missing, REPL/exec in use?>\n",
      "\n",
      "  @jit #(target='cuda:1')\n",
      "/tmp/ipykernel_63728/2804947012.py:5: NumbaWarning: \n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"matrix_comp\" failed type inference due to: Cannot determine Numba type of <class 'numba.core.dispatcher.LiftedLoop'>\n",
      "\n",
      "File \"../../../../../tmp/ipykernel_63728/2804947012.py\", line 8:\n",
      "<source missing, REPL/exec in use?>\n",
      "\n",
      "  @jit #(target='cuda:1')\n",
      "/home/gulerlab/miniconda3/envs/finite-field-env/lib/python3.9/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"matrix_comp\" was compiled in object mode without forceobj=True, but has lifted loops.\n",
      "\n",
      "File \"../../../../../tmp/ipykernel_63728/2804947012.py\", line 5:\n",
      "<source missing, REPL/exec in use?>\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/home/gulerlab/miniconda3/envs/finite-field-env/lib/python3.9/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected. This is deprecated behaviour that will be removed in Numba 0.59.0.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"../../../../../tmp/ipykernel_63728/2804947012.py\", line 5:\n",
      "<source missing, REPL/exec in use?>\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "/tmp/ipykernel_63728/2804947012.py:5: NumbaWarning: \n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"matrix_comp\" failed type inference due to: No implementation of function Function(<built-in function setitem>) found for signature:\n",
      " \n",
      " >>> setitem(array(float64, 3d, C), int64, list(array(uint16, 1d, C))<iv=None>)\n",
      " \n",
      "There are 16 candidate implementations:\n",
      "      - Of which 16 did not match due to:\n",
      "      Overload of function 'setitem': File: <numerous>: Line N/A.\n",
      "        With argument(s): '(array(float64, 3d, C), int64, list(array(uint16, 1d, C))<iv=None>)':\n",
      "       No match.\n",
      "\n",
      "During: typing of setitem at /tmp/ipykernel_63728/2804947012.py (12)\n",
      "\n",
      "File \"../../../../../tmp/ipykernel_63728/2804947012.py\", line 12:\n",
      "<source missing, REPL/exec in use?>\n",
      "\n",
      "  @jit #(target='cuda:1')\n",
      "/home/gulerlab/miniconda3/envs/finite-field-env/lib/python3.9/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"matrix_comp\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"../../../../../tmp/ipykernel_63728/2804947012.py\", line 8:\n",
      "<source missing, REPL/exec in use?>\n",
      "\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/home/gulerlab/miniconda3/envs/finite-field-env/lib/python3.9/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected. This is deprecated behaviour that will be removed in Numba 0.59.0.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"../../../../../tmp/ipykernel_63728/2804947012.py\", line 8:\n",
      "<source missing, REPL/exec in use?>\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.37607717514038\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "d=11173962\n",
    "iter_no=5\n",
    "user_no=1\n",
    "A1=np.empty((int(d/6),iter_no,user_no))\n",
    "start=time.time()\n",
    "A1=matrix_comp(A1,A_conc1,d,iter_no)\n",
    "end=time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(A1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "del A_conc1\n",
    "torch.cuda.empty_cache()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.138633012771606\n"
     ]
    }
   ],
   "source": [
    "from scipy import linalg\n",
    "import time\n",
    "\n",
    "#print(A)\n",
    "#A=np.array(A)\n",
    "#p,*_ = linalg.lstsq(A[:,:,0], e)\n",
    "d=11173962\n",
    "\n",
    "user_gradient=[]\n",
    "check_gradient=[]\n",
    "ind1=int(d/6)\n",
    "num_users=user_no\n",
    "start=time.time()   \n",
    "for user in range(num_users):\n",
    "#for user in user_no:\n",
    "    user_gradient.append([])\n",
    "    #check_gradient.append(original_gradient[user])\n",
    "for t in range(ind1):\n",
    "    #A_big[t]=np.array(A_big[t])\n",
    "    #e[t]=np.array(e[t])\n",
    "        #p,*_ = linalg.lstsq(A1[t], agg1[t])\n",
    "    p, *_  = linalg.lstsq(A1[t], agg1[t][0:iter_no])\n",
    "    #print(p)\n",
    "    for user in range(num_users):\n",
    "        user_gradient[user].append(p[user])\n",
    "    \n",
    "#check_gradient[user]=original_gradient[user]\n",
    "end=time.time()\n",
    "# ind1=int(d/3)\n",
    "# estimated_grad=least_square(A1,agg1,ind1)\n",
    "# end=time.time()\n",
    "\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.]\n",
      "1862327\n"
     ]
    }
   ],
   "source": [
    "print(p)\n",
    "print(len(user_gradient[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "o=np.load(\"original_grad.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.69873238e-06  2.07172707e-06  5.37931919e-06  1.31875277e-06\n",
      "  2.86847353e-07  3.24845314e-06 -1.11851841e-06  1.34110451e-07\n",
      " -1.18538737e-05 -1.13449059e-05]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(o[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m100\u001b[39m:\u001b[38;5;241m110\u001b[39m][:,\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43muser_gradient\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m100\u001b[39m:\u001b[38;5;241m110\u001b[39m])\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(o[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m:ind1][:,\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m-\u001b[39muser_gradient[\u001b[38;5;241m1\u001b[39m]))\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "print(o[1][100:110][:,0])\n",
    "print(user_gradient[1][100:110])\n",
    "print(np.linalg.norm(o[1][0:ind1][:,0]-user_gradient[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"gradient11_500.npy\",user_gradient)\n",
    "print(\"finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
