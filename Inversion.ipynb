{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import argparse\n",
    "# matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "import torch.nn as nn # import modules\n",
    "\n",
    "from utils.sampling import mnist_iid, mnist_noniid, cifar_iid\n",
    "from utils.options import args_parser\n",
    "from models_v1.Update import LocalUpdate\n",
    "from models_v1.Nets import MLP, CNNMnist, CNNCifar, LeNet, CNNMnist2, MobileNetV2, LeNet5, LeNet10\n",
    "from models_v1.Fed import FedAvg\n",
    "from models_v1.Fed import FedQAvg, Quantization, Quantization_Finite, my_score, my_score_Finite\n",
    "from models_v1.test import test_img\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from torch.autograd import grad\n",
    "parser = argparse.ArgumentParser(description='Deep Leakage from Gradients.')\n",
    "parser.add_argument('--index', type=int, default=\"25\",\n",
    "                    help='the index for leaking images on CIFAR.')\n",
    "parser.add_argument('--image', type=str,default=\"\",\n",
    "                    help='the path to customized image.')\n",
    "args = parser.parse_args([])\n",
    "from torch.autograd import grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_argument:    \n",
    "    epochs = 400    #\"rounds of training\"\n",
    "    num_users = 5 # \"number of users: K\"\n",
    "    frac = 0.5 #\"the fraction of clients: C\"\n",
    "    local_ep=5 #\"the number of local epochs: E\"\n",
    "    local_bs=10000 #\"local batch size: B\"\n",
    "    bs=128 #\"test batch size\"\n",
    "    lr=0.001 #\"learning rate\"\n",
    "    momentum=0.5 # \"SGD momentum (default: 0.5)\"\n",
    "    split='user' # \"train-test split type, user or sample\"\n",
    "    weight_decay = 5e-4\n",
    "    opt = 'ADAM'\n",
    "\n",
    "    # model arguments\n",
    "    model = 'cnn'\n",
    "    kernel_num=9 #, help='number of each kind of kernel')\n",
    "    kernel_sizes='3,4,5' #  help='comma-separated kernel size to use for convolution')\n",
    "    norm='batch_norm' #, help=\"batch_norm, layer_norm, or None\")\n",
    "    num_filters=32 #, help=\"number of filters for conv nets\")\n",
    "    max_pool='True' #help=\"Whether use max pooling rather than strided convolutions\")\n",
    "\n",
    "    # other arguments\n",
    "    dataset='cifar' #, help=\"name of dataset\")\n",
    "    iid=1\n",
    "    num_classes=10#, help=\"number of classes\")\n",
    "    num_channels=3#, help=\"number of channels of imges\")\n",
    "    gpu=1#, help=\"GPU ID, -1 for CPU\")\n",
    "    stopping_rounds=10#, help='rounds of early stopping')\n",
    "    verbose='False'#, help='verbose print')\n",
    "    seed=1#, help='random seed (default: 1)')\n",
    "    \n",
    "args = my_argument()\n",
    "\n",
    "args.device = torch.device('cuda:{}'.format(args.gpu) if torch.cuda.is_available() and args.gpu != -1 else 'cpu')\n",
    "\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(use_cuda)\n",
    "args.device = torch.device(\"cpu\")\n",
    "args.device = torch.device(\"cuda:1\" if use_cuda else \"cpu\")\n",
    "print(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = 'ConvNet64'\n",
    "arch='cnn'\n",
    "arch='ResNet18'\n",
    "num_images = args.num_users\n",
    "trained_model = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inversefed\n",
    "setup = inversefed.utils.system_startup()\n",
    "defs = inversefed.training_strategy('conservative')\n",
    "dm = torch.as_tensor(inversefed.consts.cifar10_mean, **setup)[:, None, None]\n",
    "ds = torch.as_tensor(inversefed.consts.cifar10_std, **setup)[:, None, None]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn, trainloader, validloader =  inversefed.construct_dataloaders('CIFAR10', defs)\n",
    "def plot(tensor):\n",
    "    tensor = tensor.clone().detach()\n",
    "    tensor.mul_(ds).add_(dm).clamp_(0, 1)\n",
    "    if tensor.shape[0] == 1:\n",
    "        return plt.imshow(tensor[0].permute(1, 2, 0).cpu());\n",
    "    else:\n",
    "        fig, axes = plt.subplots(1, tensor.shape[0], figsize=(12, tensor.shape[0]*12))\n",
    "        for i, im in enumerate(tensor):\n",
    "            axes[i].imshow(im.permute(1, 2, 0).cpu());\n",
    "num_users=args.num_users\n",
    "index=[1290,1245,1110,410,1270]\n",
    "index=[2661, 5723, 6633, 7758, 1245 ]\n",
    "#index=[301,302,303,304,305]\n",
    "index=[4434, 5723, 410, 1455,467 ]\n",
    "ground_truth, labels = [], []\n",
    "ground_truth_joint,labels_joint=[],[]\n",
    "for i in range(num_users):\n",
    "    ground_truth.append([])\n",
    "    labels.append([])\n",
    "idx = 0 # choosen randomly ... just whatever you want\n",
    "    #while len(labels) < num_images:\n",
    "index=[1290, 410, 303, 1245, 5585 ]\n",
    "index=[1290,1245,1110,410,1270]\n",
    "#index=[5723, 410, 2661, 1245, 5585 ]\n",
    "index=[5723, 410, 2661, 1245, 5585 ]\n",
    "index= [305, 410, 4434, 1455, 8034]\n",
    "index=[301, 302,303, 304, 305]\n",
    "index=[303, 305, 4434, 410, 5723]\n",
    "index=[4434, 5723, 410, 1455,467 ] #This one is also in the list\n",
    "index=[1567, 3149, 3532, 1694, 770]\n",
    "index=[4434, 3149, 3532, 410,1455]\n",
    "for i in range(num_users):\n",
    "    print(i)\n",
    "    img, label = validloader.dataset[index[idx]]\n",
    "    idx += 1\n",
    "    labels[i].append(torch.as_tensor((label,), device=setup['device']))\n",
    "    ground_truth[i].append(img.to(**setup))\n",
    "    ground_truth[i] = torch.stack(ground_truth[i])\n",
    "    ground_truth_joint.append(img.to(**setup))\n",
    "    \n",
    "    labels[i] = torch.cat(labels[i])\n",
    "    labels_joint.append(torch.as_tensor((label,), device=setup['device']))\n",
    "    plot(ground_truth[i]);\n",
    "    #plt.show()\n",
    "    print([validloader.dataset.classes[l] for l in labels[i]]);\n",
    "\n",
    "\n",
    "# In[35]:\n",
    "\n",
    "\n",
    "ground_truth_joint = torch.stack(ground_truth_joint)\n",
    "labels_joint = torch.cat(labels_joint)\n",
    "\n",
    "\n",
    "# In[36]:\n",
    "\n",
    "\n",
    "plot(ground_truth_joint);\n",
    "plt.savefig(\"original2.png\")\n",
    "print([validloader.dataset.classes[l] for l in labels_joint]);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "local_lr = 1e-4\n",
    "local_steps = 1\n",
    "use_updates = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A=torch.load(\"Model.pt\")\n",
    "print(A)\n",
    "net_glob, _ = inversefed.construct_model(arch, num_classes=10, num_channels=3)\n",
    "#print(net_glob.state_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_glob.to(**setup)\n",
    "#print(net_glob.state_dict())\n",
    "#net_glob.zero_grad()\n",
    "#print(net_glob.state_dict())\n",
    "target_loss, _, _ = loss_fn(net_glob(ground_truth[0]), labels[0])\n",
    "input_gradient=inversefed.reconstruction_algorithms.loss_steps(net_glob, ground_truth[0], labels[0], \n",
    "                                                        lr=local_lr, local_steps=local_steps,\n",
    "                                                                   use_updates=use_updates)\n",
    "net_glob.load_state_dict(A)\n",
    "w=net_glob.state_dict()\n",
    "net_glob.zero_grad()\n",
    "net_glob.zero_grad()\n",
    "#print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u1=np.load(\"gradient11.npy\")\n",
    "u2=np.load(\"gradient22.npy\")\n",
    "u3=np.load(\"gradient33.npy\")\n",
    "u4=np.load(\"gradient44.npy\")\n",
    "u5=np.load(\"gradient55.npy\")\n",
    "u6=np.load(\"gradient66.npy\")\n",
    "user_gradient=[]\n",
    "for i in range(args.num_users):\n",
    "    user_gradient.append([])\n",
    "for i in range(args.num_users):\n",
    "    user_gradient[i]=np.concatenate((u1[i],u2[i],u3[i], u4[i], u5[i], u6[i]),axis=0)\n",
    "backup_gradient=user_gradient\n",
    "print(len(user_gradient[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_lr = 1e-4\n",
    "local_steps = 1\n",
    "use_updates = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_gradient=np.load(\"original_grad.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sum_FedAvg_tensor=input_gradient[0]\n",
    "flat=[]\n",
    "count=0\n",
    "u=0\n",
    "#user_gradient=[[]]*args.num_users\n",
    "for user in range(args.num_users):\n",
    "    #user_gradient[user]=backup_gradient[user]\n",
    "    user_gradient[user]=backup_gradient[user]\n",
    "print(backup_gradient[1][0:10])\n",
    "print(user_gradient[1][0:10])\n",
    "user_gradient_tensor=[]\n",
    "#for user in idxs_users:\n",
    "#user_gradient[u]=o[u]\n",
    "print(len(user_gradient[u]))\n",
    "user_gradient_tensor=input_gradient\n",
    "\n",
    "flat=[]\n",
    "count=0\n",
    "print(user_gradient[1][0:10])\n",
    "for j in range(len(user_gradient_tensor)): # 4 layers in parameter\n",
    "    flat.append([])\n",
    "    #for h in range(len(model_diff[user])):\n",
    "for h in range(len(user_gradient_tensor)):\n",
    "    #print(user_gradient[u])\n",
    "#for h in user_gradient_tensor.keys():\n",
    "    s=list(user_gradient_tensor[h].shape)\n",
    "        #print(s)\n",
    "    if (len(s)==0):\n",
    "        new=np.array(0)\n",
    "        user_gradient[u]=np.delete(user_gradient[u],np.s_[0])\n",
    "    else:\n",
    "        #print(user_gradient[u])\n",
    "        z=np.prod(list(user_gradient_tensor[h].shape))\n",
    "        flat[count]=user_gradient[u][0:z] # taking out the vector for the specified layer\n",
    "        user_gradient[u]=np.delete(user_gradient[u],np.s_[0:z])# deleting that vector from decoded after taking out\n",
    "            \n",
    "        new=np.array(flat[count]).reshape(list(user_gradient_tensor[h].shape)) #reshaping back to the marix\n",
    "              \n",
    "    user_gradient_tensor[h]=torch.from_numpy(new).to(torch.device(\"cuda\")) #converting the matrix to a tensor\n",
    "            #print(w_glob[cluster_no][h].shape)\n",
    "    count=count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat=[]\n",
    "count=0\n",
    "\n",
    "# user_gradient_tensor=[]\n",
    "# #for user in idxs_users:\n",
    "# for user in range(0,num_users):\n",
    "#     #user_gradient_tensor.append(model_diff[user])\n",
    "#     #user_gradient_tensor=model_diff[user]\n",
    "#     #print(user_gradient_tensor)\n",
    "#     user_gradient[user]=backup_gradient[user]\n",
    "#     user_gradient_tensor.append(input_gradient[0])\n",
    "\n",
    "#     flat=[]\n",
    "#     count=0\n",
    "#     for j in range(len(input_gradient[user])): # 4 layers in parameter\n",
    "#         flat.append([])\n",
    "#     #for h in range(len(model_diff[user])):\n",
    "#     for h in range(len(user_gradient_tensor[user])):\n",
    "#         s=list(user_gradient_tensor[user][h].shape)\n",
    "#         if (len(s)==0):\n",
    "#            new=np.array(0)\n",
    "#            user_gradient[user]=np.delete(user_gradient[user],np.s_[0])\n",
    "#         else:\n",
    "#            z=np.prod(list(user_gradient_tensor[user][h].shape))\n",
    "#            flat[count]=user_gradient[user][0:z] # taking out the vector for the specified layer\n",
    "#            user_gradient[user]=np.delete(user_gradient[user],np.s_[0:z])# deleting that vector from decoded after taking out\n",
    "            \n",
    "#            new=np.array(flat[count]).reshape(list(user_gradient_tensor[user][h].shape)) #reshaping back to the marix\n",
    "              \n",
    "#         user_gradient_tensor[user][h]=torch.from_numpy(new).to(torch.device(\"cuda\")) #converting the matrix to a tensor\n",
    "#             #print(w_glob[cluster_no][h].shape)\n",
    "#         count=count+1\n",
    "\n",
    "\n",
    "\n",
    "#This has been taken from Geiping's paper's code for gradient inversion available at https://github.com/JonasGeiping/invertinggradients\n",
    "\n",
    "config = dict(signed=True,\n",
    "              boxed=True,\n",
    "              cost_fn='sim',\n",
    "              indices='def',\n",
    "              weights='equal',\n",
    "              lr=0.01,\n",
    "              optim='adam',\n",
    "              restarts=8,\n",
    "              max_iterations=24000,\n",
    "              total_variation=1e-6,\n",
    "              init='randn',\n",
    "              filter='none',\n",
    "              lr_decay=True,\n",
    "              scoring_choice='loss')\n",
    "\n",
    "#rec_machine = inversefed.GradientReconstructor(model, (dm, ds), config, num_images=num_images)\n",
    "#rec_machine =  inversefed.FedAvgReconstructor(model, (dm, ds), local_steps, local_lr, config,\n",
    "                                             #use_updates=use_updates, num_images=num_images)\n",
    "for user in range(0,1):\n",
    "     rec_machine =  inversefed.FedAvgReconstructor(net_glob, (dm, ds), local_steps, local_lr, config,\n",
    "                                             use_updates=use_updates, num_images=1)\n",
    "     output, stats = rec_machine.reconstruct(user_gradient_tensor, labels[u], img_shape=(3, 32, 32))\n",
    "\n",
    "     test_mse = (output.detach() - ground_truth[u]).pow(2).mean()\n",
    "     feat_mse = (net_glob(output.detach())- net_glob(ground_truth[u])).pow(2).mean()  \n",
    "     test_psnr = inversefed.metrics.psnr(output, ground_truth[u], factor=1/ds)\n",
    "\n",
    "     plot(output)\n",
    "     plt.title(f\"Rec. loss: {stats['opt']:2.4f} | MSE: {test_mse:2.4f} \"\n",
    "           f\"| PSNR: {test_psnr:4.2f} | FMSE: {feat_mse:2.4e} |\");\n",
    "     plt.savefig(\"recovered2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(output))\n",
    "#print(output)\n",
    "torch.save(output, \"frog_blue_topK_new_1000.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output2=torch.load(\"frog_blue_topK_new_1000.pt\")\n",
    "plot(output2)\n",
    "test_mse = (output2.detach() - ground_truth[u]).pow(2).mean()\n",
    "print(test_mse)\n",
    "feat_mse = (net_glob(output2.detach())- net_glob(ground_truth[u])).pow(2).mean()  \n",
    "test_psnr = inversefed.metrics.psnr(output2, ground_truth[u], factor=1/ds)\n",
    "print(feat_mse)\n",
    "print(test_psnr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u=4\n",
    "output2=torch.load(\"output_0.pt\")\n",
    "#plot(output2)\n",
    "output2=output2[0]\n",
    "test_mse = (output2.detach() - ground_truth[u]).pow(2).mean()\n",
    "print(test_mse)\n",
    "# feat_mse = (net_glob(output2.detach())- net_glob(ground_truth[u])).pow(2).mean()  \n",
    "# test_psnr = inversefed.metrics.psnr(output2, ground_truth[u], factor=1/ds)\n",
    "# print(feat_mse)\n",
    "# print(test_psnr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(output2)\n",
    "torch.save(output2, \"bird_randK_400.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output2=torch.load(\"horse_topK2.pt\")\n",
    "plot(output2)\n",
    "test_mse = (output2.detach() - ground_truth[u]).pow(2).mean()\n",
    "print(test_mse)\n",
    "print(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(f\"Rec. loss: {stats['opt']:2.4f} | MSE: {test_mse:2.4f} \"\n",
    "#           f\"| PSNR: {test_psnr:4.2f} | FMSE: {feat_mse:2.4e} |\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_psnr)\n",
    "print(test_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(input_gradient))\n",
    "print(flat[count])\n",
    "print(backup_gradient[u])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(count)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(backup_gradient[u])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
